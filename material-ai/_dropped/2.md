## How transformers are trained

- **Trying to guess the next token**: At the base layer, LLMs are based on the idea of predicting the next token in a sequence. When dealing with text, this can be roughly translated to predicting the next word in a sentence.
- **Learning from the data**: The model is trained on a large dataset, including books, articles and websites, to learn the patterns in the text. The more data the model is trained on, the better it can predict the next token.
- **Human feedback**: The model is then tuned to generate text that is more likely to be rated as "good" by a human.

So, overall, with some simplifications, we could say that the model is trained to predict the next word that:

- seems likely based on its training data
- is likely to be rated as "good" by a human.